---
src: ./cover.md
theme: default
class: text-center
highlighter: shiki
mdc: true
drawings:
  persist: false
image: /side-logo.png
selectable: true
title: Ubiquitous Computing, Clouds, IoT e Smart Environments
author: Pablo Leon Rodrigues
export:
  format: pdf
  timeout: 30000
  withClicks: false
---

---

## Sum√°rio

- Bancos de Dados Distribu√≠dos
- Armazenamento de dados Distribu√≠dos
- Transa√ß√µes
- Transa√ß√µes distribu√≠das
- 2PC
- 3PC

---

| Banco de Dados Distribu√≠do                                 | Banco de Dados Centralizado                                      |
|------------------------------------------------------------|------------------------------------------------------------------|
| V√°rios arquivos de banco de dados s√£o armazenados em locais distintos. | √â composto por um √∫nico arquivo de banco de dados.              |
| M√∫ltiplas pessoas podem acessar e alterar os dados ao mesmo tempo. | Gargalos ocorrem quando muitos usu√°rios acessam o mesmo arquivo simultaneamente. |
| Os arquivos s√£o enviados rapidamente a partir da localiza√ß√£o mais pr√≥xima do usu√°rio. | √â poss√≠vel que a entrega de arquivos aos usu√°rios leve mais tempo. |
| Os dados podem ser recuperados se um dos sites falhar.     | Em caso de falha do sistema, um √∫nico site representa indisponibilidade total. |
| √â necess√°ria a sincroniza√ß√£o de v√°rios arquivos de diferentes bancos. | Em um sistema central, √© mais f√°cil atualizar e gerenciar os dados. |

---
layout: two-cols
---

### Conceitos Fundamentais

- BDD: Cole√ß√£o de bases de dados logicamente integradas, mas fisicamente distribu√≠das por uma rede de computadores.

- SGBD-D: Sistema Gerenciador de Banco de Dados Distribu√≠do. Respons√°vel por manter a transpar√™ncia da distribui√ß√£o para o usu√°rio final.

Transpar√™ncia em BDD abrange:

- Localiza√ß√£o
- Fragmenta√ß√£o
- Replica√ß√£o
- Transa√ß√µes distribu√≠das

::right::

Necessidade de descentraliza√ß√£o e alta disponibilidade.

Ex: empresas com v√°rias filiais, redes de hot√©is, aplicativos m√≥veis, controle militar, etc.

- Confiabilidade
- Desempenho
- Expans√£o facilitada

---
layout: two-cols
---

### Armazenamento Distribu√≠do

O armazenamento pode ocorrer de tr√™ formas, `Fragmenta√ß√£o`, `Replica√ß√£o` ou `H√≠brido`.

#### H√≠brido:

Combina Fragmenta√ß√£o e Replica√ß√£o, onde os fragmentos podem ser replicados para garantir disponibilidade e desempenho.

Isso traz flexibilidade, mas aumenta a complexidade do gerenciamento.


::right::

#### Replica√ß√£o

A replica√ß√£o consiste em manter c√≥pias dos mesmos dados em mais de um local. Isso melhora a disponibilidade, resili√™ncia a falhas e pode aumentar o desempenho de leitura.

- **Total**: a rela√ß√£o inteira (tabela) √© replicada.
- **Parcial**: apenas parte dos dados √© replicada (linhas ou colunas espec√≠ficas).
- **S√≠ncrona**: c√≥pias atualizadas em tempo real (maior custo de comunica√ß√£o).
- **Ass√≠ncrona**: c√≥pias atualizadas periodicamente (pode haver inconsist√™ncia tempor√°ria).

---
layout: two-cols
---

#### Fragmenta√ß√£o

Em vez de duplicar dados, a fragmenta√ß√£o os divide entre os n√≥s

- **Horizontal**: Fragmenta a tabela por linhas onde cada fragmento cont√©m um subconjunto das linhas da tabela original. Reconstru√ß√£o via UNION, √∫til quando diferentes regi√µes acessam subconjuntos dos dados.

```sql
SELECT * FROM clientes_USA
UNION
SELECT * FROM clientes_Europa;
```

::right::

- **Vertical**: Fragmenta a tabela por colunas. Cada fragmento cont√©m subconjuntos de colunas, com a chave prim√°ria replicada. Reconstru√ß√£o via JOIN. √ötil quando diferentes aplica√ß√µes precisam de partes diferentes dos dados.

```sql
SELECT * FROM clientes_nome
JOIN clientes_endereco USING (id_cliente);
```

---

| Modelo        | No 1                  | No 2                  | No 3                  | No n                  |
|---------------|------------------------|------------------------|------------------------|------------------------|
| **Centralizado** | ABCD EFGH IJKL <br> MNOP QRST UVXZ |                        |                        |                        |
| **Fragmentado**  | ABC <br> DEF          | GHI <br> JKL           | MNO <br> PQR           | STU <br> VXZ           |
| **Replicado**    | ABCD EFGH IJKL <br> MNOP QRST UVXZ | ABCD EFGH IJKL <br> MNOP QRST UVXZ | ABCD EFGH IJKL <br> MNOP QRST UVXZ | ABCD EFGH IJKL <br> MNOP QRST UVXZ |
| **H√≠brido**      | ABCD <br> EFGH        | ABCD EFGH <br> IJKL    | IJKL MNOP <br> QRST    | UVXZ                   |


---

#### Vantagens do Armazenamento Distribu√≠do

- Desempenho: consultas podem ser resolvidas localmente, evitando tr√°fego de rede.

- Toler√¢ncia a falhas: se um n√≥ falhar, os dados ainda est√£o dispon√≠veis em outro.

- Escalabilidade: voc√™ pode adicionar n√≥s e distribuir mais dados conforme necess√°rio.

- Localidade dos dados: acesso mais r√°pido aos dados onde s√£o mais usados.

---

### Transa√ß√µes

Uma transa√ß√£o √© uma sequ√™ncia l√≥gica de opera√ß√µes (como INSERT, UPDATE, DELETE, SELECT) que deve ser executada como uma √∫nica unidade at√¥mica.

Uma transa√ß√£o tem como objetivo manter o estado consistente do banco de dados, mesmo com m√∫ltiplos acessos simult√¢neos, falhas ou interrup√ß√µes.

#### Exemplo cl√°ssico: Transfer√™ncia banc√°ria

Suponha que Alice transfere R$100 para Bob:
- Debita R$100 da conta de Alice
- Credita R$100 na conta de Bob

Se qualquer etapa falhar, a transa√ß√£o inteira deve ser cancelada. Nenhuma mudan√ßa parcial deve permanecer.

---

### Transa√ß√µes Distribu√≠das
Em sistemas distribu√≠dos, as transa√ß√µes envolvem m√∫ltiplos bancos de dados (ou servidores/n√≥s).

**Componentes:**

- Cliente: quem inicia a transa√ß√£o.
  - Planas (flat): modelo cl√°ssico, com in√≠cio, commit/rollback e fim.
  - Aninhadas (nested): podem conter subtransa√ß√µes dentro da principal. A subtransa√ß√£o pode falhar e ser anulada sem comprometer a transa√ß√£o-pai.
- Participantes: servidores que det√™m os dados envolvidos, fazem o join e executam suas opera√ß√µes locais.
- Coordenador: gerencia o commit da transa√ß√£o em todos os n√≥s e determina se a transa√ß√£o pode ser finalizada com sucesso.

---
layout: two-cols
---

#### Poss√≠veis Estados de uma Transa√ß√£o

As transa√ß√µes podem apresentar estados durante o andamento do processo.

- Ativa: est√° sendo executada.
- Parcialmente conclu√≠da: terminou todas as opera√ß√µes.
- Falhou: uma das opera√ß√µes falhou.
- Abortada: revertida (rollback).
- Confirmada: todas as opera√ß√µes foram conclu√≠das com sucesso (commit).

::right::

#### Cen√°rios de Falha

Dentre as falhas que podem acontecer est√£o:

- Falha de rede: perda de conex√£o entre coordenador e participantes.
- Falha de participante: um servidor reinicia ou trava.
- Falha do coordenador: sistema entra em per√≠odo de incerteza.

---

### Concorr√™ncia em BDD

Diversas t√©cnicas s√£o utilizadas para gerenciar a concorr√™ncia em sistemas de banco de dados distribu√≠dos, incluindo:

- Bloqueio (Locking): Transa√ß√µes adquirem bloqueios sobre os dados que precisam acessar, impedindo que outras transa√ß√µes os modifiquem simultaneamente. Em sistemas distribu√≠dos, o gerenciamento de bloqueios pode ser centralizado ou distribu√≠do.

- Timestamp Ordering: Cada transa√ß√£o recebe um timestamp, e as opera√ß√µes s√£o executadas na ordem dos timestamps para garantir a serializabilidade.

- Controle de Concorr√™ncia Otimista: Assume que conflitos s√£o raros e permite que as transa√ß√µes sejam executadas sem bloqueios. No final, as transa√ß√µes s√£o validadas para verificar se houve conflitos. Se houver, uma ou mais transa√ß√µes s√£o desfeitas (rollback).

- Protocolos de Commit At√¥mico: Garantem que uma transa√ß√£o distribu√≠da seja confirmada em todos os n√≥s envolvidos ou seja desfeita em todos eles, mantendo a consist√™ncia global. O protocolo Two-Phase Commit (2PC) √© um exemplo comum.

---

Em bancos de dados distribu√≠dos (BDD) travas e bloqueios s√£o mecanismos desenvolvidos para garantir controle de concorr√™ncia, ou seja, evitar que transa√ß√µes concorrentes acessem simultaneamente os mesmos dados de forma conflitante.

As travas funcionam como uma forma de reservar o acesso a um recurso (registro, tabela, etc.) para uma √∫nica transa√ß√£o por vez.

Um exemplo de trava √© o `Uso exclusivo por chegada: 1 e 2`, nesse tipo de trada

- A primeira transa√ß√£o a chegar adquire a trava e tem uso exclusivo do recurso.
- A segunda (ou demais) transa√ß√µes devem aguardar a libera√ß√£o da trava.
- Isso √© t√≠pico em travas de leitura/escrita exclusivas, onde a exclusividade evita condi√ß√µes de corrida (race conditions).

---

#### Problema comum: Deadlock (impasse)

Quando m√∫ltiplas transa√ß√µes ficam esperando travas que s√≥ ser√£o liberadas se outra transa√ß√£o terminar, pode haver ciclo de espera, formando um deadlock.

Um deadlock ocorre quando duas ou mais transa√ß√µes est√£o esperando indefinidamente por recursos que est√£o sendo mantidos umas pelas outras. Isso cria um ciclo de depend√™ncia sem sa√≠da.

Exemplo cl√°ssico:

- Transa√ß√£o T1 trava o Recurso A e precisa do Recurso B.
- Transa√ß√£o T2 trava o Recurso B e precisa do Recurso A.
- T1 e T2 ficam esperando indefinidamente uma pela outra ‚Üí deadlock.

Estrat√©gias para lidar com deadlocks:
- Preven√ß√£o: ordem pr√©-definida de travamento ou travar todos os objetos no in√≠cio.
- Detec√ß√£o: constru√ß√£o de grafo de espera, procurando por ciclos.
- Timeout: se uma transa√ß√£o demorar demais para adquirir uma trava, ela √© abortada automaticamente.

---
layout: two-cols
---

#### Controle Otimista (Optimistic Concurrency Control - OCC)

O OCC parte do princ√≠pio de que conflitos entre transa√ß√µes s√£o raros, e por isso n√£o utiliza travas durante a execu√ß√£o normal das transa√ß√µes.

"Deixa todo mundo trabalhar √† vontade, e s√≥ no final a gente verifica se deu tudo certo."

üõ† **Fase de Execu√ß√£o (ou Tentativa)**
- A transa√ß√£o executa livremente, sem bloquear dados.
- Manipula c√≥pias locais ou vers√µes tempor√°rias dos dados (sem afetar os dados reais).

::right::


üõ† **Fase de Valida√ß√£o**
- Antes de finalizar, o sistema verifica se houve conflito com outras transa√ß√µes (ex: uma escrita em dado que foi lido).
- Se n√£o houve conflito, a transa√ß√£o pode prosseguir.
- Se houve conflito, a transa√ß√£o √© abortada e reiniciada.

üõ† **Fase de Atualiza√ß√£o**
- Os dados modificados s√£o aplicados ao banco real.
- Isso ocorre de forma at√¥mica, garantindo consist√™ncia.

<!--
Onde √© √∫til? Sistemas com baixo √≠ndice de conflitos.

Ambientes distribu√≠dos, onde usar travas pode ser custoso.
Aplica√ß√µes com muito mais leituras do que escritas (ex: dashboards, BI, sistemas de consulta).

‚úÖ Vantagens
Evita deadlocks (n√£o h√° travas durante execu√ß√£o).
Alta taxa de paralelismo.
Boa performance em ambientes com poucas colis√µes.

‚ö†Ô∏è Desvantagens
Pode haver repetidas reexecu√ß√µes de transa√ß√µes em ambientes com muitos conflitos.
Desperd√≠cio de recursos se muitas transa√ß√µes forem abortadas na valida√ß√£o.

Imagina dois clientes tentando atualizar o mesmo saldo banc√°rio:

Ambos leem o saldo = 100
Cliente A faz +50, Cliente B faz -30
Na fase de valida√ß√£o, o sistema v√™ que ambos leram o mesmo dado e tentaram escrever
Apenas um ter√° permiss√£o para escrever (o outro ser√° abortado)
-->

---
layout: two-cols
---

#### Controle por Marca√ß√£o Temporal (Timestamp Ordering)

Cada transa√ß√£o recebe um timestamp (carimbo de tempo) √∫nico no momento em que come√ßa.
Todas as opera√ß√µes (leitura/escrita) da transa√ß√£o devem respeitar a ordem temporal estabelecida por esses timestamps.

"Quem chega primeiro, tem prioridade."

Cada dado no banco mant√©m:
- TS_W(X) = timestamp da √∫ltima escrita no dado X
- TS_R(X) = timestamp da √∫ltima leitura no dado X

::right::

üßæ 1. Leitura de X por transa√ß√£o T:

- Permitida se TS(T) ‚â• TS_W(X) ‚Üí transa√ß√£o √© mais nova que a √∫ltima escrita.
- Aborta se TS(T) < TS_W(X) ‚Üí transa√ß√£o est√° lendo dado que j√° foi sobrescrito por outra mais nova.

‚úçÔ∏è 2. Escrita de X por transa√ß√£o T:
- Permitida se TS(T) ‚â• TS_R(X) e TS(T) ‚â• TS_W(X)
- Aborta se a transa√ß√£o for mais velha que alguma leitura ou escrita j√° feita ‚Üí violaria a ordem.

<!--

‚úÖ Vantagens
Sem deadlocks
‚Üí√£o usa travas. Portanto, n√£o h√° espera circular.
Transa√ß√µes serializ√°veis
A ordem dos timestamps assegura uma execu√ß√£o correta (equivalente a uma serial).

Boa para ambientes altamente concorrentes
Especialmente onde ordem temporal √© importante.

‚ö†Ô∏è Desvantagens
Transa√ß√µes podem ser abortadas com frequ√™ncia
Principalmente se os timestamps forem muito pr√≥ximos ou mal distribu√≠dos.

Pouco controle de reexecu√ß√£o
Transa√ß√£o abortada deve ser reiniciada do zero, com um novo timestamp.

Exemplo
Imagina duas transa√ß√µes:
T1 (timestamp 5): quer ler X
T2 (timestamp 10): j√° escreveu X
Se T1 tentar ler X agora, ela ser√° abortada, porque sua leitura violaria a ordem: ela estaria lendo um valor que foi atualizado por uma transa√ß√£o mais nova (T2).

Timestamps podem vir de rel√≥gios l√≥gicos (como Lamport) ou f√≠sicos (sincronizados com NTP).
Ideal quando se quer garantir ordena√ß√£o causal ou tempo real.
Usado como base em sistemas sem travas como o Spanner (Google) ou certos bancos baseados em MVCC.
-->

---
layout: piramede
---

::center::

#### MVCC (Multiversion Concurrency Control)?

MVCC permite que v√°rias vers√µes de um mesmo dado coexistam no sistema, de forma que

- Leituras n√£o bloqueiam escritas
- Escritas n√£o bloqueiam leituras
- Cada transa√ß√£o v√™ uma vis√£o consistente do banco de dados, como se fosse "congelada no tempo"

‚ÄúCada transa√ß√£o enxerga o mundo como ele era no momento em que come√ßou.‚Äù

::left::

Leitura:
- A transa√ß√£o l√™ a vers√£o mais recente do dado que foi criada antes dela iniciar
- Ignora altera√ß√µes feitas por transa√ß√µes que ainda n√£o tinham sido finalizadas

::right::

Escrita:
- Ao modificar um dado, o sistema n√£o sobrescreve a vers√£o atual, em vez disso, cria uma nova vers√£o com novo timestamp
- As vers√µes antigas permanecem para transa√ß√µes mais antigas ainda em andamento

<!--
‚úÖ Vantagens:
Leituras consistentes e sem bloqueios (√≥timo para workloads com muitas consultas)
Evita conflitos desnecess√°rios entre leitores e escritores
N√£o h√° deadlock entre transa√ß√µes de leitura

‚ö†Ô∏è Desvantagens:
Ac√∫mulo de vers√µes antigas ‚Üí precisa de mecanismo de limpeza (garbage collection)
Pode haver custo adicional de armazenamento e gerenciamento de vers√µes

Bancos que usam MVCC:
PostgreSQL
Oracle
Couchbase
Spanner (Google)
TiDB
CockroachDB
-->

---

#### Controle baseado em Votos (Quorum-Based Protocols)

Nesse protocolo cada opera√ß√£o (leitura ou escrita) precisa de permiss√£o de um subconjunto dos n√≥s que mant√™m r√©plicas do dado, esse subconjunto √© chamado de quorum.

- Atribui√ß√£o de Votos: Cada n√≥ no sistema distribu√≠do recebe um certo n√∫mero de votos. Esse n√∫mero pode ser igual para todos os n√≥s ou variar dependendo de fatores como capacidade ou confiabilidade.

- Defini√ß√£o de Qu√≥runs: S√£o definidos dois tipos de qu√≥runs:
  - Qu√≥rum de Leitura (Read Quorum - VR): O n√∫mero m√≠nimo de votos necess√°rios para realizar uma opera√ß√£o de leitura em um determinado item de dados.
  - Qu√≥rum de Escrita (Write Quorum - VW): O n√∫mero m√≠nimo de votos necess√°rios para realizar uma opera√ß√£o de escrita em um determinado item de dados.

---
layout: two-cols
---

##### Regras para Consist√™ncia

Para garantir a consist√™ncia dos dados, os qu√≥runs de leitura e escrita devem obedecer √†s seguintes regras:

- VR + VW > V: A soma dos qu√≥runs de leitura e escrita deve ser maior que o n√∫mero total de votos (V) no sistema. Isso garante que sempre haver√° uma interse√ß√£o entre um qu√≥rum de leitura e um qu√≥rum de escrita, o que significa que uma leitura sempre obter√° a vers√£o mais recente dos dados.
- VW > V/2: O qu√≥rum de escrita deve ser maior que a metade do n√∫mero total de votos. Isso garante que apenas uma opera√ß√£o de escrita possa ser realizada por vez, evitando conflitos de escrita.

::right::

##### Opera√ß√µes de Leitura e Escrita

<br>

- Leitura: Para ler um item de dados, uma transa√ß√£o precisa obter um qu√≥rum de leitura (VR) de votos dos n√≥s que armazenam o item. A transa√ß√£o pode ent√£o ler o valor do item de qualquer n√≥ que fa√ßa parte do qu√≥rum de leitura.
- Escrita: Para escrever um item de dados, uma transa√ß√£o precisa obter um qu√≥rum de escrita (VW) de votos dos n√≥s que armazenam o item. A transa√ß√£o ent√£o envia a nova vers√£o do item para todos os n√≥s que fazem parte do qu√≥rum de escrita.

<!--
‚úÖ Vantagens:
Garante consist√™ncia forte, mesmo com r√©plicas distribu√≠das.
Alta toler√¢ncia a falhas (se V_r e V_w forem bem escolhidos).
Escalabilidade: n√£o precisa de coordena√ß√£o global.

‚ö†Ô∏è Desvantagens:
Pode ser ineficiente em leitura ou escrita, se os valores de quorum forem altos.
Lat√™ncia aumentada: exige m√∫ltiplos acessos simult√¢neos.
Mais complexo de gerenciar em compara√ß√£o com modelos baseados em travas simples.

Exemplo
Sistemas com dados replicados (como Cassandra, DynamoDB, etc.).
Ambientes que exigem disponibilidade alta e escalabilidade.
Quando se quer flexibilidade entre consist√™ncia e desempenho (ex: leitura r√°pida vs. escrita confi√°vel).

Considere um sistema com 5 n√≥s, onde cada n√≥ tem 1 voto. Podemos definir VR = 3 e VW = 3.
Para ler um item, precisamos obter 3 votos. Podemos ler de qualquer combina√ß√£o de 3 n√≥s.
Para escrever um item, precisamos obter 3 votos. Precisamos escrever em qualquer combina√ß√£o de 3 n√≥s.
Como VR + VW (3 + 3 = 6) √© maior que V (5) e VW (3) √© maior que V/2 (2.5), as regras de consist√™ncia s√£o satisfeitas.

-->

---


#### Resumo Comparativo de T√©cnicas de Controle de Concorr√™ncia

| T√©cnica                    | Usa travas? | Toler√¢ncia a falhas | Deadlock? | Ideal para...                    |
|---------------------------|-------------|----------------------|-----------|----------------------------------|
| **Lock-based**            | Sim         | Baixa                | Sim       | Ambientes com muitos conflitos  |
| **Otimista (OCC)**        | N√£o         | Alta                 | N√£o       | Baixo conflito, leitura intensa |
| **Timestamp Ordering**    | N√£o         | Alta                 | N√£o       | Aplica√ß√µes com ordem temporal   |
| **MVCC** (Multiversion)   | Sim (internamente) | Alta        | N√£o       | Leitura massiva, alta concorr√™ncia |
| **Quorum/Vota√ß√£o**        | Sim/N√£o     | Alta                 | Depende   | Controle de r√©plicas distribu√≠das |


---
layout: two-cols
---

### ACID

ACID √© um conceito que se refere √†s quatro propriedades de transa√ß√£o de um sistema de banco de dados...

#### Atomicidade (Atomicity)

A transa√ß√£o deve ser executada por completo ou n√£o ter efeito nenhum, se ocorrer uma falha no meio do caminho, todas as altera√ß√µes parciais devem ser desfeitas (rollback).

Exemplo: Se uma transfer√™ncia banc√°ria falhar ap√≥s o d√©bito, o cr√©dito tamb√©m n√£o deve acontecer.

#### Consist√™ncia (Consistency)

O banco de dados deve estar em um estado consistente antes e depois da transa√ß√£o, regras de integridade (como chaves estrangeiras, dom√≠nios de valores, etc.) devem ser respeitadas.

Exemplo: Um saldo nunca pode ficar negativo se isso viola as regras do sistema.

::right::

#### Isolamento (Isolation)

Transa√ß√µes simult√¢neas n√£o devem interferir entre si, o resultado da execu√ß√£o de v√°rias transa√ß√µes concorrentes deve ser o mesmo que se fossem executadas em s√©rie (serializa√ß√£o).

Exemplo: Dois clientes sacando ao mesmo tempo devem ver o saldo correto, sem conflito de leitura/escrita.

#### Durabilidade (Durability)

Ap√≥s uma transa√ß√£o ser confirmada (commit), suas altera√ß√µes devem persistir mesmo ap√≥s falhas como quedas de energia ou travamentos, isso √© garantido por mecanismos como grava√ß√£o em log de transa√ß√µes e uso de mem√≥ria est√°vel (como disco).

---

### ACID em Bancos de Dados Distribu√≠dos

No contexto distribu√≠do, ACID se torna mais desafiador, especialmente por conta de:

- Comunica√ß√£o entre n√≥s distantes (falhas e atrasos)
- Sincroniza√ß√£o de commits (protocolo 2PC √© usado para isso)
- Garantir isolamento entre transa√ß√µes que acessam n√≥s diferentes

---

### Two-Phase Commit Protocol (2PC)

O 2PC (Protocolo de Comprometimento em Duas Fases) √© um Atomic Commitment Protocol, ele visa garantir que todos os participantes de uma transa√ß√£o distribu√≠da concordem sobre confirmar ou abortar a transa√ß√£o.

Agentes 2PC:

- Coordenador: gerencia a transa√ß√£o.
- Participantes: executam opera√ß√µes locais e seguem as ordens do coordenador.

Como o pr√≥prio nome sugere, esse protocoloco ocorre em duas fases, a `Vota√ß√£o ou Prepara√ß√£o` e a `Decis√£o`.

---
layout: two-cols
---

#### Fase 1: Vota√ß√£o (prepare/vote phase)

O coordenador envia `canCommit?` para todos os participantes.

**Cada participante:**
- Executa a transa√ß√£o localmente.
- Se tudo estiver ok:
  - Entra em estado preparado.
  - Envia `vote-commit`.
  - Garante localmente que pode efetivar (sem voltar atr√°s).
- Se n√£o puder:
  - Envia `vote-abort`.

::right::

#### Fase 2: Decis√£o (commit/abort phase)

O coordenador coleta os votos:

- Se TODOS votaram `commit`:
  - Envia `doCommit` para todos.
- Se ALGUM votou `abort`:
  - Envia `doAbort` para todos.

**Cada participante:**
- Executa o commit ou abort local.
- Envia confirma√ß√£o (`haveCommitted` ou `haveAborted`) de volta ao coordenador.

---

```mermaid {scale: 0.55}
sequenceDiagram
  participant C as Coordenador
  participant A as Participante A
  participant B as Participante B
  participant D as Participante C

  Note over C A B D: Fase 1 - Vota√ß√£o (Prepara√ß√£o)

  C->>A: canCommit?
  C->>B: canCommit?
  C->>D: canCommit?

  A-->>C: YES
  B-->>C: YES
  D-->>C: YES

  Note over C A B D: Fase 2 - Decis√£o

  C->>A: doCommit
  C->>B: doCommit
  C->>D: doCommit

  A-->>C: haveCommitted
  B-->>C: haveCommitted
  D-->>C: haveCommitted
```

---

```mermaid {scale: 0.68}
sequenceDiagram
  participant C as Coordenador
  participant A as Participante A
  participant B as Participante B
  participant D as Participante C

  Note over C A B D: Fase 1 - Vota√ß√£o (Prepara√ß√£o)

  C->>A: canCommit?
  C->>B: canCommit?
  C->>D: canCommit?

  A-->>C: YES
  B-->>C: NO
  D-->>C: YES

  Note over C A B D: Fase 2 - Cancelamento

  C->>A: doAbort
  C->>B: doAbort
  C->>D: doAbort
```

---

#### Falhas e Per√≠odo de Incerteza

Um dos pontos cr√≠ticos do 2PC √© o per√≠odo de incerteza, que ocorre quando, o participante votou commit, mas ainda n√£o recebeu o doCommit (porque o coordenador caiu).

Nesse momento, ele n√£o sabe o destino da transa√ß√£o.

Estrat√©gias:
- Consultar outros participantes. (Generais Bizantinos, 3PC)
- Aguardar at√© o coordenador voltar. (TimeOut?)
- Reconfigurar com protocolos mais robustos (como 3PC).

---
layout: two-cols
---

#### Vantagens

<br>

- Amplamente implementado
- Garante consist√™ncia global mesmo com falhas locais
- √â mais simples que outros protocolos como o 3PC

::right::

#### Desvantagens

<br>

- Custo do 2PC
  - Com N participantes: ~3N mensagens
  - Rodadas de comunica√ß√£o, 3 fases de mensagens (pedido, resposta, decis√£o)
- Pode causar bloqueios prolongados no caso de falhas
- Exige mais mensagens e tempo de espera
- Desempenho
  Simples e confi√°vel, mas lento para sistemas com muitas transa√ß√µes concorrentes ou sujeitos a falhas.

---

### Three-Phase Commit (3PC)

O Three-Phase Commit √© um protocolo de efetiva√ß√£o at√¥mica n√£o bloqueante, que tenta garantir que nenhum participante fique preso em um estado indefinido em caso de falha do coordenador.

Ele introduz uma fase intermedi√°ria chamada "prepare to commit", criando 3 fases no total.

<br>

#### Fase 1: CanCommit (Consulta de Voto)

- Igual ao 2PC.
- O coordenador pergunta aos participantes se est√£o prontos para efetivar a transa√ß√£o.

Participantes respondem:
- YES: prontos
- NO: n√£o podem efetivar

---
layout: two-cols
---

#### Fase 2: PreCommit (Preparar para Commit)

Se todos os votos forem YES, o coordenador envia `prepare` ou `preCommit`

Participantes:
- Executam as a√ß√µes necess√°rias
- Gravem tudo em log
- N√£o efetivam ainda, mas ficam prontos para isso
- Enviam de volta ACK

Aqui est√° o ponto chave: se o coordenador falhar agora, os participantes t√™m autonomia suficiente para decidir sozinhos o que fazer (com base no log e nos outros participantes).

::right::

#### Fase 3: Commit

Ap√≥s receber todos os ACK, o coordenador envia `doCommit`
- Participantes efetivam e confirmam.

Resumo do fluxo
1. canCommit?  ‚Üí Participantes respondem YES/NO
2. preCommit   ‚Üí Participantes preparam, gravam log, enviam ACK
3. doCommit    ‚Üí Participantes efetivam

---

### üìä Comparativo: Two-Phase Commit (2PC) vs Three-Phase Commit (3PC)

| Caracter√≠stica            | 2PC (Two-Phase Commit)           | 3PC (Three-Phase Commit)            |
|---------------------------|----------------------------------|-------------------------------------|
| üîÑ N√∫mero de Fases        | 2                                | 3                                   |
| üß± Fases                  | canCommit, doCommit/Abort        | canCommit, preCommit, doCommit      |
| üîí Bloqueio Poss√≠vel      | Sim (estado de incerteza)        | Reduzido (usa fase intermedi√°ria)   |
| üí• Toler√¢ncia a Falhas    | Limitada                         | Maior (participantes t√™m autonomia) |
| üß† Autonomia dos N√≥s      | Baixa (esperam coordenador)      | Alta (decidem em caso de falha)     |
| üì® Overhead de Mensagens  | Menor                            | Maior (mensagens adicionais)        |
| ‚öôÔ∏è Complexidade           | Menor                            | Maior (l√≥gica e logs adicionais)    |
| üß™ Aplica√ß√£o Pr√°tica      | Mais comum                       | Raro (substitu√≠do por algoritmos de consenso) |

<!-- Raft ou Paxos -->

---

O 3PC ainda n√£o √© 100% √† prova de falhas, especialmente com falhas simult√¢neas ou parti√ß√µes de rede.

- Introduz mais mensagens e overhead.
- Pouco usado na pr√°tica, sistemas modernos preferem usar:
  - Algoritmos baseados em consenso (como Raft ou Paxos)
  - Compensa√ß√µes (eventual consistency) em sistemas de alta disponibilidade

---

‚ÄãAtualmente, os Bancos de Dados Distribu√≠dos (BDD) mais utilizados incluem:‚Äã

MongoDB: Banco de dados NoSQL orientado a documentos, amplamente adotado para aplica√ß√µes que requerem escalabilidade horizontal e flexibilidade no esquema de dados. ‚Äã

Cassandra: Banco de dados NoSQL de coluna larga, projetado para lidar com grandes volumes de dados distribu√≠dos em m√∫ltiplos n√≥s, garantindo alta disponibilidade e toler√¢ncia a falhas.‚Äã

Amazon DynamoDB: Servi√ßo de banco de dados NoSQL totalmente gerenciado, conhecido por sua escalabilidade autom√°tica e desempenho de lat√™ncia √∫nica de d√≠gitos em milissegundos. ‚Äã

Microsoft Azure Cosmos DB: Banco de dados multimodelo distribu√≠do globalmente, oferecendo suporte a v√°rios modelos de dados e APIs, com lat√™ncia baixa e garantias de consist√™ncia ajust√°veis. ‚Äã
DB-Engines

Google Cloud Spanner: Banco de dados relacional distribu√≠do que combina a escalabilidade dos bancos NoSQL com a consist√™ncia e familiaridade dos bancos SQL tradicionais.


---

<img class="m-auto -z-5 max-w-full max-h-full" style="background-color: white" src="/ddb.png"/>










